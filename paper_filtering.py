import statistics
from dataclasses import dataclass
from typing import Sequence

from arxiv_api_client import get_papers, Paper
from arxiv_api_tool import paper_to_str
from pydantic import BaseModel, Field
from model import get_llm
from parse_config import get_interests
import time
from langchain_core.prompts import PromptTemplate

rating_prompt_template = PromptTemplate.from_template("Rate the novelty, clarity and impact of the following papers. Provide a comment on why the paper might be interesting. \n\n\n {papers}")


class PaperRating(BaseModel):
    """Rating of an ArXiv paper."""
    paper_id: str = Field(description="The arxiv id of the paper")
    title: str = Field(description="The title of the paper")
    novelty: int = Field(description="How novel the idea of the paper is (1-5)")
    clarity: int = Field(description="How understandable the presented idea is (1-5)")
    impact: int = Field(description="How impactful the paper might be (1-5)")
    comment: str = Field(description="Why the paper might be interesting (one sentence)")

class PaperRatings(BaseModel):
    paper_ratings: Sequence[PaperRating] = Field(..., description="Ratings of the papers")

@dataclass
class PaperWithRatings:
    paper: Paper
    ratings: PaperRating

    def __str__(self):
        return paper_to_str(self.paper) + "\n"+f"Average paper rating: {get_summary_paper_score(self.ratings)}"


def get_summary_paper_score(paper_rating: PaperRating)->float:
    """
    Using scores for novelty, clarity and impact generated by the LLM, average them to a single score for the paper.
    :param paper_rating: Object containing the paper ratings
    :return: Mean rating of the paper
    """
    return statistics.mean([paper_rating.novelty, paper_rating.clarity, paper_rating.impact])

def get_papers_with_ratings()->Sequence[PaperWithRatings]:
    """
    Get papers and their ratings for recently published papers from the domains the user is interested in.
    :return: Sequence of PaperWithRatings objects
    """
    interests = get_interests()
    papers = []
    for interest in interests:
        papers.extend(get_papers(interest, 20, 0, True))
        time.sleep(3.5) # ArXiv API has a 1 request per 3 seconds rate limit
    papers_str = [paper_to_str(x) for x in papers]
    papers_str = "\n---\n".join(papers_str)
    llm = get_llm()
    structured_llm_json = llm.with_structured_output(PaperRatings, method="json_schema")

    # Gemini-2.5-flash has a 1M context window so splitting up the documents is likely not needed - they're just abstracts

    prompt = rating_prompt_template.format(papers=papers_str)
    result = structured_llm_json.invoke(
        prompt
    )

    papers_with_ratings = []
    for rating in result.paper_ratings:
        paper_id = rating.paper_id
        paper = next((x for x in papers if paper_id in x.id), None)
        papers_with_ratings.append(PaperWithRatings(paper, rating))

    return papers_with_ratings

def sort_papers(papers_with_ratings: Sequence[PaperWithRatings])->Sequence[PaperWithRatings]:
    """
    Sort an iterable of PaperWithRatings objects according to their summary rating.
    :param papers_with_ratings: The papers (with ratings) to process.
    :return: The papers sorted by descending average score.
    """
    papers_by_score = list(papers_with_ratings)
    papers_by_score.sort(key=lambda p: get_summary_paper_score(p.ratings), reverse=True)
    return papers_by_score

def get_most_interesting_papers(n: int)->Sequence[PaperWithRatings]:
    """
    Get n most interesting, recently published papers from the domains the user is interested in.
    :param n: Number of papers to return
    :return: Iterable of PaperWithRatings sorted by descending average score.
    """
    ratings = get_papers_with_ratings()
    sorted_papers = sort_papers(ratings)
    return sorted_papers[:n]

if __name__ == "__main__":
    for x in get_most_interesting_papers(10):
        print(x)